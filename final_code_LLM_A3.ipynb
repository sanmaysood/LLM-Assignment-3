{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN3wb2v1oNCE"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes torch transformers peft datasets accelerate trl einops pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hAZDNuaqoOgI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig, pipeline, DataCollatorWithPadding, GenerationConfig, HfArgumentParser, TrainerCallback\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "2973c91b642d4d88a2a38fec3cd1aa23",
      "f30ea95062614da8a3f52be45ac9f0c4",
      "e1193dcb05eb4f6091e7d4bcf2b4cd52",
      "dd76545f326642868cc12e6af146ae98",
      "4a5ff5a4984d4d169e318beaeef3b3ae",
      "994d80e11b2245e2885d1a3534895696",
      "31a898baed194fec87c55e8b705b722d",
      "b49c44420b6746e8b346ed22212a1492",
      "44d969a41268484b9aba28c1125f61ef",
      "0f1d46a49e284b0299110b4d2c2a6878",
      "85dccc268497454c93025622af866f09"
     ]
    },
    "id": "V0s0Sz_2UwPR",
    "outputId": "6da7b608-d6cc-4e4d-ee25-6fc58791bc22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2973c91b642d4d88a2a38fec3cd1aa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "snli = load_dataset('snli')\n",
    "test_dataset = snli['test'].select(range(0, 10000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ppa8qLZWvzdq"
   },
   "outputs": [],
   "source": [
    "def create_prompt(premise, hypothesis):\n",
    "    return f\"\"\"Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n",
    "    0 : Hypothesis entails the Premise\n",
    "    1 : Neutral\n",
    "    2 : Hypothesis does not entail the Premise\n",
    "    Output only one single numerical value.\n",
    "\n",
    "    Premise: {premise}\n",
    "    Hypothesis: {hypothesis}\n",
    "\n",
    "    Output:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQl0o6M4VvSZ",
    "outputId": "3ae64282-08e1-4670-def1-6bd6a68b1c8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_dataset)\n",
    "failure_cases = []\n",
    "\n",
    "for i, sample in enumerate(test_dataset):\n",
    "\n",
    "    prompt = create_prompt(sample['premise'], sample['hypothesis'])\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    original_model.to(input_ids.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = original_model.generate(input_ids, max_length=input_ids.size(1)+64)\n",
    "\n",
    "    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    answer = None\n",
    "    try:\n",
    "        answer = int((output.split(\"Output:\\n\")[-1].strip().split(\"\\n\")[0]).split(\" \")[0])\n",
    "    except:\n",
    "        answer = None\n",
    "\n",
    "    if answer is not None and answer == sample['label']:\n",
    "        correct += 1\n",
    "    else:\n",
    "        failure_cases.append({\n",
    "            \"premise\": sample['premise'],\n",
    "            \"hypothesis\": sample['hypothesis'],\n",
    "            \"predicted_label\": answer,\n",
    "            \"actual_label\": sample['label']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FSMA1zrtdmV",
    "outputId": "f618704e-83ab-4af3-b658-47afcea8f739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before fine-tuning: 59.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/total\n",
    "print(f\"Accuracy before fine-tuning: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQ_8r8rc_VOT",
    "outputId": "3e273da4-f45c-4f5a-a820-2a47b809d11d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'This church choir sings to the masses as they sing joyous songs from the book at a church.',\n",
       "  'hypothesis': 'The church has cracks in the ceiling.',\n",
       "  'predicted_label': 2,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A woman within an orchestra is playing a violin.',\n",
       "  'hypothesis': 'A woman is playing the violin.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'Two men climbing on a wooden scaffold.',\n",
       "  'hypothesis': 'Two sad men climbing on a wooden scaffold.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A group of people stand near and on a large black square on the ground with some yellow writing on it.',\n",
       "  'hypothesis': 'a group of people wait',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A Skier ski-jumping while two other skiers watch his act.',\n",
       "  'hypothesis': 'A skier preparing a trick',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'Children bathe in water from large drums.',\n",
       "  'hypothesis': 'The kids are wet.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A woman is standing near three stores, two have beautiful artwork and the other store has Largo written on it.',\n",
       "  'hypothesis': 'A woman standing on a street corner outside beside three different stores, two of which contain beautiful artwork and one with a Largo sign.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man is renovating a room.',\n",
       "  'hypothesis': 'A man is using a hammer in a room.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'An Ambulance is passing a man wearing a bandanna and girl.',\n",
       "  'hypothesis': 'The man in the bandana is running after the ambulance',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'The Sooner football player carrying the ball is trying to avoid being tackled.',\n",
       "  'hypothesis': 'A football player is holding a ball.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'An older gentleman wearing a hat is walking on crutches next to a busy street.',\n",
       "  'hypothesis': 'A man with a walking stick is next to the street.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A female marathon runner wearing a red headband, a red tank top and black shorts jogging down a paved road.',\n",
       "  'hypothesis': 'two women arm wrestle in a bar',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Two men playing in a beautiful lake surrounded by mountains.',\n",
       "  'hypothesis': 'A couple people enjoy the water near the mountains.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'Two middle-aged police officers watch over a parking lot, at night.',\n",
       "  'hypothesis': 'The officers are actually security guards.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A bicycle rider wearing racing gear pedals a yellow bike past the wire fence at the edge of a field, with a stand of trees in the background.',\n",
       "  'hypothesis': 'A scooter rider wearing casual clothes races past a building.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man in a purple mascot costume is standing outside of a store while a man and a woman each wearing flamboyant clothing stand off to the side.',\n",
       "  'hypothesis': 'The costume is green.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Bubbles surround a statue in the middle of a street.',\n",
       "  'hypothesis': 'There are bubbles around the statue.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man in a tie-dyed shirt and jeans is sitting on a bench with a dog and a guitar on his lap, as well as a harmonica near his mouth.',\n",
       "  'hypothesis': 'A guy is next to a dog while holding some musical instruments.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man in an orange jacket reaches under a busted up blue car on wooden supports.',\n",
       "  'hypothesis': 'A man reaches into a boat.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Two boys inside a fence jump in the air while holding a basketball.',\n",
       "  'hypothesis': 'Two boys sit down.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A woman in an American military uniform sits at a table and writes the words \"sad,\" \"depressed,\" and \"hatred\" on a large sheet of white paper.',\n",
       "  'hypothesis': 'A woman is diving off a mountain.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Man with black shirt and sunglasses makes something out of a balloon.',\n",
       "  'hypothesis': 'A man makes something from a balloon.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A red dog jumps and catches a tennis ball in its mouth.',\n",
       "  'hypothesis': 'a dog catching a ball he just got as a gift',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A female swimmer wearing a swimming cap does the butterfly stroke.',\n",
       "  'hypothesis': 'A woman is sitting beside a pool.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Group of young adults posing for picture near spanish-language sign.',\n",
       "  'hypothesis': 'The people are taking a science test.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man sitting and a woman laying in his lap kissing each other.',\n",
       "  'hypothesis': 'A couple are preparing to be intimate.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'man doing carpentry or construction on top of an unfinished building.',\n",
       "  'hypothesis': 'The man tore down the shed.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A light technician man with tribal tattoos aiming a spotlight over a balcony.',\n",
       "  'hypothesis': 'An actress takes the stage.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'It looks like quite a sweaty, smelly dog pile over one little rugby ball, but the boys in blue seem to want it more.',\n",
       "  'hypothesis': 'A little boy looks disgusted that is ball is dirty',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A woman in a red shirt looks at a map while with a view of a river and several boats in the background.',\n",
       "  'hypothesis': 'A woman looks at a map outdoors, a river and boats are behind her.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man with two small boys making a purchase from a woman.',\n",
       "  'hypothesis': 'The little boys are flying a kite with the man and the woman.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man and a woman are holding hands on the shore of a lake.',\n",
       "  'hypothesis': 'A couple on vacation.',\n",
       "  'predicted_label': 0,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A man and a child are laughing at each other.',\n",
       "  'hypothesis': 'Two people are laughing.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A tattooed woman clicking on a mouse on a desk.',\n",
       "  'hypothesis': 'A tattooed man clicking on a mouse on a desk.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A guy in a red jacket is snowboarding in midair.',\n",
       "  'hypothesis': 'A guy is outside in the snow',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'Passengers in a rusty yellow car driving down the street.',\n",
       "  'hypothesis': 'A car drives on a street.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'Two women are hugging on a path through a grassy area with a cow visible past them.',\n",
       "  'hypothesis': 'They are at the bar',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man wearing a purple cap, yellow snow goggles, a periwinkle jacket and red backpack moves quickly through powdery snow near a winter tree.',\n",
       "  'hypothesis': 'A man is moving quickly through the snow.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A group of students are walking through the campus.',\n",
       "  'hypothesis': 'A group of people are walking together',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man on a sidewalk is playing the accordion while happy people pass by.',\n",
       "  'hypothesis': 'A man performs for the public',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A person attempts to rope a black cow while riding a horse.',\n",
       "  'hypothesis': 'The person is on a camel.',\n",
       "  'predicted_label': 1,\n",
       "  'actual_label': 2}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kJsqtCx90RPM"
   },
   "outputs": [],
   "source": [
    "original_model = prepare_model_for_kbit_training(original_model)\n",
    "original_model.gradient_checkpointing_enable()\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir = \"./logs\",\n",
    "    num_train_epochs = 5,\n",
    "    warmup_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = 2,\n",
    "    gradient_checkpointing = False,\n",
    "    learning_rate = 4e-4,\n",
    "    optim = \"paged_adamw_32bit\",\n",
    "    group_by_length = True,\n",
    "    logging_steps = 100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r = 32,\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules = ['q_proj','k_proj','v_proj','dense']\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(original_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA1qwKgwserb"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def create_prompt(sample):\n",
    "\n",
    "    return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n",
    "    0 : Hypothesis entails the Premise\n",
    "    1 : Neutral\n",
    "    2 : Hypothesis does not entail the Premise\n",
    "    Output only one single numerical value.\n",
    "\n",
    "    Premise: {sample['premise']}\n",
    "    Hypothesis: {sample['hypothesis']}\n",
    "\n",
    "### Output: {sample['label']}\n",
    "### End\"\"\"\n",
    "\n",
    "\n",
    "def preprocess_dataset(tokenizer, dataset):\n",
    "\n",
    "    # Format prompt for each sample\n",
    "    dataset = dataset.map(lambda x: {\"text\": create_prompt(x)})\n",
    "\n",
    "    # Tokenize the text; ensure we use the correct field from the dataset\n",
    "    tokenized_dataset = dataset.map(\n",
    "        lambda x: tokenizer(x['text'], max_length=2048, truncation=True),\n",
    "        batched=True,\n",
    "        remove_columns=['premise', 'hypothesis', 'label']\n",
    "    )\n",
    "\n",
    "    # Filter by max_length and shuffle dataset\n",
    "    tokenized_dataset = tokenized_dataset.filter(lambda x: len(x[\"input_ids\"]) < 2048).shuffle(seed=423)\n",
    "\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_qiM998ha6hx"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "train_dataset = preprocess_dataset(tokenizer, snli['train'].select(range(0, 550000, 550)))\n",
    "val_dataset = preprocess_dataset(tokenizer, snli['validation'].select(range(0, 10000, 100)))\n",
    "peft_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZOJP5s9G8LAc"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "\n",
    "def log_resource_usage():\n",
    "    # CPU and memory usage\n",
    "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)  # in GB\n",
    "    cpu_usage = psutil.cpu_percent(interval=1)  # in %\n",
    "\n",
    "    # GPU usage (if CUDA is available)\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.memory_allocated(0) / (1024 ** 3)  # in GB\n",
    "        gpu_memory_reserved = torch.cuda.memory_reserved(0) / (1024 ** 3)  # in GB\n",
    "        gpu_utilization = torch.cuda.utilization(0)\n",
    "        print(f\"GPU Usage - Memory Allocated: {gpu_memory:.2f} GB, Memory Reserved: {gpu_memory_reserved:.2f} GB, Utilization: {gpu_utilization}%\")\n",
    "    else:\n",
    "        gpu_memory = 0\n",
    "        gpu_utilization = 0\n",
    "        print(\"No GPU available.\")\n",
    "\n",
    "    print(f\"CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "0fnRSzTcWygB",
    "outputId": "40463f67-aa74-4f08-b058-090a8b4b5f2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 22:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.529073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491600</td>\n",
       "      <td>0.519329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.517142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.520770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.527814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End of Epoch 1.0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage - Memory Allocated: 2.55 GB, Memory Reserved: 3.41 GB, Utilization: 0%\n",
      "CPU Usage: 3.5%, Memory Usage: 2.79 GB\n",
      "\n",
      "End of Epoch 2.0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage - Memory Allocated: 2.55 GB, Memory Reserved: 4.15 GB, Utilization: 0%\n",
      "CPU Usage: 3.5%, Memory Usage: 2.80 GB\n",
      "\n",
      "End of Epoch 3.0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage - Memory Allocated: 2.55 GB, Memory Reserved: 4.15 GB, Utilization: 0%\n",
      "CPU Usage: 2.0%, Memory Usage: 2.81 GB\n",
      "\n",
      "End of Epoch 4.0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage - Memory Allocated: 2.55 GB, Memory Reserved: 4.15 GB, Utilization: 0%\n",
      "CPU Usage: 3.0%, Memory Usage: 2.82 GB\n",
      "\n",
      "End of Epoch 5.0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage - Memory Allocated: 2.55 GB, Memory Reserved: 4.15 GB, Utilization: 0%\n",
      "CPU Usage: 3.5%, Memory Usage: 2.99 GB\n"
     ]
    }
   ],
   "source": [
    "# Custom callback to log resource usage after each epoch\n",
    "class ResourceLoggingCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        print(f\"\\nEnd of Epoch {state.epoch}/{args.num_train_epochs}\")\n",
    "        log_resource_usage()\n",
    "\n",
    "# Initialize the trainer with the custom callback\n",
    "peft_trainer = transformers.Trainer(\n",
    "    model=peft_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    args=training_arguments,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    callbacks=[ResourceLoggingCallback()]  # Register the callback here\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "peft_trainer.train()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AdXdqIZCb9A",
    "outputId": "d7c30afb-7c00-48b0-cbe6-490feb0d2ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fine-tune the model using QLoRA: 22.89 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken to fine-tune the model using QLoRA: {(end_time - start_time) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGMohfKDiDuv",
    "outputId": "86677b98-cbb8-4735-bbe1-184435193349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in the model: 2,800,655,360\n",
      "Number of parameters fine-tuned: 20,971,520\n"
     ]
    }
   ],
   "source": [
    "model_save_directory = \"./fine_tuned_model\"\n",
    "peft_model.save_pretrained(model_save_directory)\n",
    "\n",
    "total_params = peft_model.num_parameters()\n",
    "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters in the model: {total_params:,}\")\n",
    "print(f\"Number of parameters fine-tuned: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "070a6ee1881643f8a27bfa647fe8b14c",
      "31f76426020449f4b1ea546c7b30192e",
      "8d703203153a4fe6bbb7354f02fac140",
      "d5d8705580734eaf996e10a084ea985f",
      "29a570455b9a40228593435bc2c6d892",
      "c7eb6598fe4e41f1860a296c68bc5ddf",
      "9d079be4e2a24d3080516aa6ee83fdb8",
      "8b03795eae914b4dac94466823d5163c",
      "3b50a9c37c1f46cfac34801ca8186822",
      "ca9335a2d38249e1beaaf909d8df794f",
      "36dbd19c9258415bb9efe0def6be4fde"
     ]
    },
    "id": "vb-gdwtHRbdN",
    "outputId": "42a229ca-49e2-4f98-9998-1dbdddf7b903"
   },
   "outputs": [],
   "source": [
    "base_model_id = \"microsoft/phi-2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id,\n",
    "                                                      device_map='auto',\n",
    "                                                      quantization_config=bnb_config,\n",
    "                                                      trust_remote_code=True)\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "eval_tokenizer.pad_token = eval_tokenizer.eos_token\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, model_save_directory,torch_dtype=torch.float16,is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpBmukDqvaKj",
    "outputId": "83b5c5a4-8778-4536-cf71-2c9ca357172d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt format function\n",
    "def format_prompt(premise, hypothesis):\n",
    "    return f\"\"\"Check whether the Hypothesis entails the Premise or not. Follow the following output format:\n",
    "    0 : Hypothesis entails the Premise\n",
    "    1 : Neutral\n",
    "    2 : Hypothesis does not entail the Premise\n",
    "    Output only one single numerical value.\n",
    "\n",
    "    Premise: {premise}\n",
    "    Hypothesis: {hypothesis}\n",
    "\n",
    "    Output:\n",
    "    \"\"\"\n",
    "\n",
    "# Tracking variables\n",
    "correct = 0\n",
    "total = len(test_dataset)\n",
    "corrected_by_finetuned = []\n",
    "not_corrected_by_finetuned = []\n",
    "pretrained_failures = failure_cases\n",
    "\n",
    "# Loop through each test sample\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    # Prepare the prompt\n",
    "    prompt = format_prompt(sample['premise'], sample['hypothesis'])\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    ft_model.to(input_ids.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = ft_model.generate(input_ids, max_length=input_ids.size(1)+10)\n",
    "\n",
    "    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    answer = None\n",
    "    try:\n",
    "        answer = int((output.split(\"Output:\\n\")[-1].strip().split(\"\\n\")[0]).split(\" \")[0])\n",
    "    except:\n",
    "        answer = None\n",
    "\n",
    "    if answer is not None and answer == sample['label']:\n",
    "        correct += 1\n",
    "\n",
    "    # Check if this case was a pre-trained model failure\n",
    "    pretrain_failure = next((f for f in pretrained_failures if f[\"premise\"] == sample['premise'] and f[\"hypothesis\"] == sample['hypothesis']), None)\n",
    "\n",
    "    if pretrain_failure:\n",
    "        # If fine-tuned model corrected it, add to corrected list; else, add to not-corrected list\n",
    "        if answer == sample['label']:\n",
    "            corrected_by_finetuned.append({\n",
    "                \"premise\": sample['premise'],\n",
    "                \"hypothesis\": sample['hypothesis'],\n",
    "                \"pretrained_predicted_label\": pretrain_failure[\"predicted_label\"],\n",
    "                \"fine_tuned_predicted_label\": answer,\n",
    "                \"actual_label\": sample['label']\n",
    "            })\n",
    "        else:\n",
    "            not_corrected_by_finetuned.append({\n",
    "                \"premise\": sample['premise'],\n",
    "                \"hypothesis\": sample['hypothesis'],\n",
    "                \"pretrained_predicted_label\": pretrain_failure[\"predicted_label\"],\n",
    "                \"fine_tuned_predicted_label\": answer,\n",
    "                \"actual_label\": sample['label']\n",
    "            })\n",
    "\n",
    "# Now `corrected_by_finetuned` contains failures corrected by fine-tuning,\n",
    "# and `not_corrected_by_finetuned` contains those still incorrect after fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zj0qv4YN7Xe3",
    "outputId": "02524a6a-ad66-4ed1-e70c-ca2cd1fc81ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after fine-tuning: 87.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/total\n",
    "print(f\"Accuracy after fine-tuning: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xg5HbfNKQ14X",
    "outputId": "378b9e28-35f9-40b0-c541-25e48f87a568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'A woman within an orchestra is playing a violin.',\n",
       "  'hypothesis': 'A woman is playing the violin.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A group of people stand near and on a large black square on the ground with some yellow writing on it.',\n",
       "  'hypothesis': 'a group of people wait',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'Children bathe in water from large drums.',\n",
       "  'hypothesis': 'The kids are wet.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man is renovating a room.',\n",
       "  'hypothesis': 'A man is using a hammer in a room.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'An Ambulance is passing a man wearing a bandanna and girl.',\n",
       "  'hypothesis': 'The man in the bandana is running after the ambulance',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'The Sooner football player carrying the ball is trying to avoid being tackled.',\n",
       "  'hypothesis': 'A football player is holding a ball.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A female marathon runner wearing a red headband, a red tank top and black shorts jogging down a paved road.',\n",
       "  'hypothesis': 'two women arm wrestle in a bar',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Two men playing in a beautiful lake surrounded by mountains.',\n",
       "  'hypothesis': 'A couple people enjoy the water near the mountains.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A bicycle rider wearing racing gear pedals a yellow bike past the wire fence at the edge of a field, with a stand of trees in the background.',\n",
       "  'hypothesis': 'A scooter rider wearing casual clothes races past a building.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man in a purple mascot costume is standing outside of a store while a man and a woman each wearing flamboyant clothing stand off to the side.',\n",
       "  'hypothesis': 'The costume is green.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Bubbles surround a statue in the middle of a street.',\n",
       "  'hypothesis': 'There are bubbles around the statue.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man in a tie-dyed shirt and jeans is sitting on a bench with a dog and a guitar on his lap, as well as a harmonica near his mouth.',\n",
       "  'hypothesis': 'A guy is next to a dog while holding some musical instruments.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man in an orange jacket reaches under a busted up blue car on wooden supports.',\n",
       "  'hypothesis': 'A man reaches into a boat.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Two boys inside a fence jump in the air while holding a basketball.',\n",
       "  'hypothesis': 'Two boys sit down.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A woman in an American military uniform sits at a table and writes the words \"sad,\" \"depressed,\" and \"hatred\" on a large sheet of white paper.',\n",
       "  'hypothesis': 'A woman is diving off a mountain.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Man with black shirt and sunglasses makes something out of a balloon.',\n",
       "  'hypothesis': 'A man makes something from a balloon.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A red dog jumps and catches a tennis ball in its mouth.',\n",
       "  'hypothesis': 'a dog catching a ball he just got as a gift',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A female swimmer wearing a swimming cap does the butterfly stroke.',\n",
       "  'hypothesis': 'A woman is sitting beside a pool.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Group of young adults posing for picture near spanish-language sign.',\n",
       "  'hypothesis': 'The people are taking a science test.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man sitting and a woman laying in his lap kissing each other.',\n",
       "  'hypothesis': 'A couple are preparing to be intimate.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'man doing carpentry or construction on top of an unfinished building.',\n",
       "  'hypothesis': 'The man tore down the shed.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A light technician man with tribal tattoos aiming a spotlight over a balcony.',\n",
       "  'hypothesis': 'An actress takes the stage.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A woman in a red shirt looks at a map while with a view of a river and several boats in the background.',\n",
       "  'hypothesis': 'A woman looks at a map outdoors, a river and boats are behind her.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A man with two small boys making a purchase from a woman.',\n",
       "  'hypothesis': 'The little boys are flying a kite with the man and the woman.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man and a woman are holding hands on the shore of a lake.',\n",
       "  'hypothesis': 'A couple on vacation.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A man and a child are laughing at each other.',\n",
       "  'hypothesis': 'Two people are laughing.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A tattooed woman clicking on a mouse on a desk.',\n",
       "  'hypothesis': 'A tattooed man clicking on a mouse on a desk.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A guy in a red jacket is snowboarding in midair.',\n",
       "  'hypothesis': 'A guy is outside in the snow',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'Passengers in a rusty yellow car driving down the street.',\n",
       "  'hypothesis': 'A car drives on a street.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'Two women are hugging on a path through a grassy area with a cow visible past them.',\n",
       "  'hypothesis': 'They are at the bar',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man wearing a purple cap, yellow snow goggles, a periwinkle jacket and red backpack moves quickly through powdery snow near a winter tree.',\n",
       "  'hypothesis': 'A man is moving quickly through the snow.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A group of students are walking through the campus.',\n",
       "  'hypothesis': 'A group of people are walking together',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 0,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A person attempts to rope a black cow while riding a horse.',\n",
       "  'hypothesis': 'The person is on a camel.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 2}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_by_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWCIo9McQ536",
    "outputId": "aa71becd-5ce3-4a98-c450-e8c3e978adb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'This church choir sings to the masses as they sing joyous songs from the book at a church.',\n",
       "  'hypothesis': 'The church has cracks in the ceiling.',\n",
       "  'pretrained_predicted_label': 2,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'Two men climbing on a wooden scaffold.',\n",
       "  'hypothesis': 'Two sad men climbing on a wooden scaffold.',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 2,\n",
       "  'actual_label': 1},\n",
       " {'premise': 'A Skier ski-jumping while two other skiers watch his act.',\n",
       "  'hypothesis': 'A skier preparing a trick',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'A woman is standing near three stores, two have beautiful artwork and the other store has Largo written on it.',\n",
       "  'hypothesis': 'A woman standing on a street corner outside beside three different stores, two of which contain beautiful artwork and one with a Largo sign.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 0},\n",
       " {'premise': 'An older gentleman wearing a hat is walking on crutches next to a busy street.',\n",
       "  'hypothesis': 'A man with a walking stick is next to the street.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'Two middle-aged police officers watch over a parking lot, at night.',\n",
       "  'hypothesis': 'The officers are actually security guards.',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'It looks like quite a sweaty, smelly dog pile over one little rugby ball, but the boys in blue seem to want it more.',\n",
       "  'hypothesis': 'A little boy looks disgusted that is ball is dirty',\n",
       "  'pretrained_predicted_label': 0,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 2},\n",
       " {'premise': 'A man on a sidewalk is playing the accordion while happy people pass by.',\n",
       "  'hypothesis': 'A man performs for the public',\n",
       "  'pretrained_predicted_label': 1,\n",
       "  'fine_tuned_predicted_label': 1,\n",
       "  'actual_label': 0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_corrected_by_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wDm9C80bRy1L",
    "outputId": "ef9b58f6-b3ed-4655-91d5-41c5f4898f27"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_60fd58ff-79ac-44c8-a2d1-01067b91be01\", \"fine_tuned_model.zip\", 77598206)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_3fcdfe44-0155-4c62-8673-7cc1b19934fe\", \"logs.zip\", 1155286643)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "shutil.make_archive('/content/fine_tuned_model', 'zip', '/content/fine_tuned_model')\n",
    "shutil.make_archive('/content/logs', 'zip', '/content/logs')\n",
    "files.download('/content/fine_tuned_model.zip')\n",
    "files.download('/content/logs.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "070a6ee1881643f8a27bfa647fe8b14c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31f76426020449f4b1ea546c7b30192e",
       "IPY_MODEL_8d703203153a4fe6bbb7354f02fac140",
       "IPY_MODEL_d5d8705580734eaf996e10a084ea985f"
      ],
      "layout": "IPY_MODEL_29a570455b9a40228593435bc2c6d892"
     }
    },
    "0f1d46a49e284b0299110b4d2c2a6878": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2973c91b642d4d88a2a38fec3cd1aa23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f30ea95062614da8a3f52be45ac9f0c4",
       "IPY_MODEL_e1193dcb05eb4f6091e7d4bcf2b4cd52",
       "IPY_MODEL_dd76545f326642868cc12e6af146ae98"
      ],
      "layout": "IPY_MODEL_4a5ff5a4984d4d169e318beaeef3b3ae"
     }
    },
    "29a570455b9a40228593435bc2c6d892": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31a898baed194fec87c55e8b705b722d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31f76426020449f4b1ea546c7b30192e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7eb6598fe4e41f1860a296c68bc5ddf",
      "placeholder": "​",
      "style": "IPY_MODEL_9d079be4e2a24d3080516aa6ee83fdb8",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "36dbd19c9258415bb9efe0def6be4fde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b50a9c37c1f46cfac34801ca8186822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44d969a41268484b9aba28c1125f61ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a5ff5a4984d4d169e318beaeef3b3ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85dccc268497454c93025622af866f09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b03795eae914b4dac94466823d5163c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d703203153a4fe6bbb7354f02fac140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b03795eae914b4dac94466823d5163c",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b50a9c37c1f46cfac34801ca8186822",
      "value": 2
     }
    },
    "994d80e11b2245e2885d1a3534895696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d079be4e2a24d3080516aa6ee83fdb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b49c44420b6746e8b346ed22212a1492": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7eb6598fe4e41f1860a296c68bc5ddf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca9335a2d38249e1beaaf909d8df794f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d8705580734eaf996e10a084ea985f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca9335a2d38249e1beaaf909d8df794f",
      "placeholder": "​",
      "style": "IPY_MODEL_36dbd19c9258415bb9efe0def6be4fde",
      "value": " 2/2 [00:27&lt;00:00, 11.83s/it]"
     }
    },
    "dd76545f326642868cc12e6af146ae98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f1d46a49e284b0299110b4d2c2a6878",
      "placeholder": "​",
      "style": "IPY_MODEL_85dccc268497454c93025622af866f09",
      "value": " 2/2 [00:23&lt;00:00, 10.31s/it]"
     }
    },
    "e1193dcb05eb4f6091e7d4bcf2b4cd52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b49c44420b6746e8b346ed22212a1492",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44d969a41268484b9aba28c1125f61ef",
      "value": 2
     }
    },
    "f30ea95062614da8a3f52be45ac9f0c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_994d80e11b2245e2885d1a3534895696",
      "placeholder": "​",
      "style": "IPY_MODEL_31a898baed194fec87c55e8b705b722d",
      "value": "Loading checkpoint shards: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
